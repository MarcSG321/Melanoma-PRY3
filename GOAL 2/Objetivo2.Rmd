---
title: "Objetivo2"
author: "Eva Cantín Larumbe"
date: "2023-04-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
```

Abrimos los datos y los limpiamos rápidamente:
```{r data}
df = read.csv("../BBDD/rep_adn_missing20_grupfuz.csv")
df = df[, -c(1,2)]
df = df[, !names(df) %in% c("Grupo_etiopatogenico","grupfuz","grupfuz3","grupfuz4")]

genes = colnames(df[,23:42])

#nos quedamos con los datos de genes de reparación
df2 = df[, c(genes, "grupfuz_todo")]
```

Estudiamos los NAs por cada gen de reparación y por cada paciente:
```{r}
#datos faltantes por variable
numNA = apply(df2, 2, function(x) sum(is.na(x)))
percNA = round(100*apply(df2,2, function(x) mean(is.na(x))), 2)
tablaNA = data.frame("Variable" = colnames(df2), numNA, percNA)
tablaNA

#datos faltantes por individuo
numNA2 = apply(df, 1, function(x) sum(is.na(x)))
percNA2 = round(100*apply(df2, 1, function(x) mean(is.na(x))), 2)
tablaNA2 = data.frame("Variable" = colnames(df2), numNA, percNA)
tablaNA2
```


Separamos la BD en X (variables explicativas) y en Y (variable explicada: grupo_etiop)

```{r train y test}
#make this example reproducible
library(caret)
set.seed(100)
trainFilas = createDataPartition(df2$grupfuz_todo, p=0.75, list=FALSE)

train = df2[trainFilas,]    
test = df2[-trainFilas,] 

y_train = as.factor(train$grupfuz_todo)
X_train = train[, !names(train) %in% c("grupfuz_todo")]
y_test =  as.factor(test$grupfuz_todo)
X_test = test[, !names(test) %in% c("grupfuz_todo")]


y = as.factor(df2$grupfuz_todo)
X = df2[,!names(df2) %in% c("grupfuz_todo")]
```


Estudiamos si hay alguna variable que es muy constante (y por tanto, se procederá a eliminarla):
```{r}
for (i in 1:ncol(X_train)) {
  # Crear un histograma con hist() para la columna actual
  hist(X_train[[i]], main = names(X_train)[i])
}
```

# PLS-DA
El primer método que vamos a probar es PLS-DA. Escalamos y centramos los datos con scaleC="standard".
```{r}
library(ropls)
myplsda = opls(x = X_train, y = y_train, crossvalI=6, scaleC = "standard", predI = 4)

#myplsda2 = opls(x=X, y=y, crossvalI=6, scaleC="standard", predI=4)
```



Para validar el modelo PLS, puede ser útil observar el valor de R^2^ y Q^2^ A la vista de los resultados del modelo, la bondad de predicción de nuestro modelo PLS con A=`r nrow(myplsda@modelDF)` componentes no es muy bueno, pues no supera el valor 0.5 (`r myplsda@modelDF[nrow(myplsda@modelDF),6]`). 

En cuanto a la bondad de ajuste, entre las `r nrow(myplsda@modelDF)` componentes obtenemos un R^2^ acumulado de `r myplsda@modelDF[nrow(myplsda@modelDF), 2]` para las X y de `r myplsda@modelDF[nrow(myplsda@modelDF), 4]` para las Y. Además, si observamos el gráfico de similaridad, concluimos que, por azar, el modelo sería menos bueno que el que ya tenemos. Si no fuese así, deberíamos replantearnos la elección de otro tipo de técnica.

No obstante, a pesar de que la función opls() nos aconseja utilizar `r nrow(myplsda@modelDF)` componentes, vamos a visualizar R^2^ y Q^2^ por si fuera conveniente escoger una componente más. Hay veces donde la Q^2^ empieza a disminuir, pero la caída es muy pequeña y se sigue pareciendo a la R2.

Recordemos que R selecciona componentes hasta donde Q^2^ empieza a disminuir. Esto se realiza para que no haya **sobreajuste** porque si aumentamos innecesariamente el número de componentes, la capacidad predictiva (Q^2^) disminuye estrepitosamente, aunque el ajuste del modelo (R^2^) aumente en gran medida.

ESTE ES EL GRÁFICO PONIENDO 4 COMPONENTES Y VIENDO QUÉ R2 Y Q2 HAY
```{r plotNC, echo=TRUE, message=FALSE, warning=FALSE}
# Visualizamos la R2
plot(1:length(myplsda@modelDF$`R2Y(cum)`), myplsda@modelDF$`R2Y(cum)`, type = "o", pch = 16, col = "#00BFC4", lwd = 2, xlab = "Components", ylab = "", ylim = c(-0.1,0.1), main = "PLS model")

# Y después la Q2
lines(1:length(myplsda@modelDF$`Q2(cum)`), myplsda@modelDF$`Q2(cum)`, type = "o", pch = 16, col = "#F8766D", lwd = 2, ylim=c(-0.1, 0.1))

# Límite en Q2
abline(h = 0.5, col = "#F8766D", lty = 2)

# lEYENDA
legend("bottomleft", c("R2Y", "Q2"), lwd = 2, col = c("#00BFC4", "#F8766D"), bty = "n")
```


## Validación del modelo


```{r T2 PLSDA, fig.width=5, fig.height=5}
#recuperamos los Scores
misScores = myplsda@scoreMN

varT = apply(misScores, 2, var) #varianza de la componente
miT2 = colSums(t(misScores**2) / varT) #calculamos la T2-Hotteling
N = nrow(X_train)
A = 2
F95 = A*(N**2 - 1)/(N*(N - A)) * qf(0.95, A, N-A); F95
F99 = A*(N**2 - 1)/(N*(N - A)) * qf(0.99, A, N-A); F99
plot(1:length(miT2), miT2, type = "l", xlab = "Pacientes", ylab = "T2",
     main = "PLS-DA: T2-Hotelling", ylim = c(0,20))
abline(h = F95, col = "orange", lty = 2, lwd = 2)
abline(h = F99, col = "red3", lty = 2, lwd = 2)

cat("Hay", length(which(miT2 > F95)), "pacientes anómalos, cuando debería haber", nrow(X_train)*0.05)

cat("\nHay", length(which(miT2 > F99)), "pacientes anómalos, cuando debería haber", nrow(X_train)*0.01)
```

Vamos a ver a qué grupos pertenecen los anómalos:

```{r}
table(train$grupfuz_todo)
table(train[which(miT2 > F95),]$grupfuz_todo)
table(train[which(miT2 > F99),]$grupfuz_todo)
```

Ver qué pasa con rowSums(myE^2). Creo que es porque hay datos faltantes en X_train.
```{r SCR PLSDA, eval=FALSE, fig.height=5, fig.width=5, include=FALSE}
myT = myplsda@scoreMN #scores
myP = myplsda@loadingMN #loadings

#IMPORTANTE
myE = scale(X_train) - myT%*%t(myP) #E = Y-XB. 

#esto no funciona bien (NAs)
mySCR = rowSums(myE^2)   # SPE 
plot(1:length(mySCR), mySCR, type = "l", main = "PLS-DA: SCR", 
     ylab = "d", xlab = "Pacientes", ylim = c(0,300))
#var(mtSCR)
g = var(mySCR)/(2*mean(mySCR))
h = (2*mean(mySCR)^2)/var(mySCR)
chi2lim = g*qchisq(0.95, df = h)
abline(h = chi2lim, col = 2, lty = 2)
```


## Interpretación del modelo
Los siguientes gráficos nos servirán para interpretar el modelo PLS. El gráfico de scores t/t es muy útil para comprender la relación entre las observaciones.

```{r}
library("randomcoloR")
set.seed(2)
colores <- distinctColorPalette(7)   

names(colores) = levels(y_train)

par(mfrow = c(1,2))
#gráfico de scores comp 1 y 2
plot(myplsda@scoreMN, col = colores[y_train], pch = 20, asp = 1,
     main = "PLS-DA: Score plot")

legend("topright", names(colores), fill = colores, bty = "n", ncol = 3)

#gráfico de loadings comp 1 y 2
plot(x = myplsda, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(1, 2), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)

#gráfico de scores comp 2 y 3
plot(myplsda@scoreMN[,2:3], col = colores[y_train], pch = 20, asp = 1,
     main = "PLS-DA: Score plot")
legend("topright", names(colores), fill = colores, bty = "n", ncol = 3)

#gráfico de loadings comp 2 y 3
plot(x = myplsda, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(2, 3), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)

#gráfico de scores comp 1 y 3
plot(myplsda@scoreMN[,c(1,3)], col = colores[y_train], pch = 20, asp = 1,
     main = "PLS-DA: Score plot")
legend("topright", names(colores), fill = colores, bty = "n", ncol = 3)

#gráfico de loadings comp 1 y 3
plot(x = myplsda, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(1, 3), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)

#gráfico de scores comp 2 y 3
plot(myplsda@scoreMN[,3:4], col = colores[y_train], pch = 20, asp = 1,
     main = "PLS-DA: Score plot")
legend("topright", names(colores), fill = colores, bty = "n", ncol = 3)

#gráfico de loadings comp 3 y 4
plot(x = myplsda, typeVc = "x-loading",
     parCexN = 0.8, parCompVi = c(3, 4), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = NA)

```



```{r}
par(mfrow=c(1,2))
plot(x = myplsda, typeVc = "x-score",
     parCexN = 0.4, parCompVi = c(1, 2), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = 0.00001, parEllipsesL=FALSE)

plot(x = myplsda, typeVc = "x-score",
     parCexN = 0.4, parCompVi = c(1, 4), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = 0.00001, parEllipsesL=FALSE)

par(mfrow=c(1,2))
plot(x = myplsda, typeVc = "x-score",
     parCexN = 0.4, parCompVi = c(1, 3), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = 0.00001, parEllipsesL=FALSE)

plot(x = myplsda, typeVc = "x-score",
     parCexN = 0.4, parCompVi = c(2, 3), parPaletteVc = NA,
     parTitleL = TRUE, parCexMetricN = 0.00001, parEllipsesL=FALSE)
```



Más gráficos:
  - Gráfico XY-weight w*c. Muestran la estructura de correlación entre X e Y. Dan información sobre  cómo las variables se combinan para formar la relación cuantitativa entre X e Y.
- Gráfico de correlación. Correlación entre las variables X e Y y las componentes PLS. 

```{r}
plot(x = myplsda, typeVc = "correlation",
     parCexN = 0.5, parCompVi = c(1, 2), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = myplsda, typeVc = "correlation",
     parCexN = 0.5, parCompVi = c(1, 4), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = myplsda, typeVc = "correlation",
     parCexN = 0.5, parCompVi = c(1, 3), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)

plot(x = myplsda, typeVc = "correlation",
     parCexN = 0.5, parCompVi = c(2, 3), parPaletteVc = NA, 
     parTitleL = TRUE, parCexMetricN = NA)
```

Una visión de la importancia global tiene cada una de las variables en nuestro modelo PLS se obtiene a partir del gráfico VIP. El VIP es una medida acumulada de la influencia de cada variable X sobre la variable Y (grupo etiopatogénico).

```{r vip}
barplot(sort(myplsda@vipVn, decreasing = TRUE), main = "VIP", las = 2, cex.names=0.5) 

abline(h = 1, col = 3, lty = 2) 
abline(h = 0.8, col = 2, lty = 2) 
```


Respecto al VIP, tenemos `r sum(myplsda@vipVn>1)` variables que sobrepasan el valor de 1. Por ello, se pueden considerar variables importantes para la predicción. Estas son: `r names(which(myplsda@vipVn>1))`. Por lo que estas variables ayudan a predecir el precio por metro cuadrado de una casa.

Además, considerando que las variables con VIP menor de 0.8 son muy poco relevantes, hemos decidido representar este valor en el gráfico. Las variables que no sobrepasan el umbral, y que por tanto no serán relevantes para la predicción son: `r names(which(mypls4@vipVn<0.8))`. Por lo que estas variables no ayudan a predecir el precio por metro cuadrado de una casa.

**NO SÉ SI HAY QUE HACERLO**
  ## Linealidad de los scores
  La linealidad de los scores es crucial estudiarla, pues si no cumpliesen con este supuesto, se tendrían que aplicar transformaciones que cambiarían completamente el modelo. 

Esta linealidad se puede estudiar utilizando el coeficiente de correlación de Pearson, que debe ser lo más próximo a 1, o haciendo un gráfico de dispersión entre los scores t y u. 

Tanto los scores de la primera componente ($t_1$ y$u_1$) como los de la segunda ($t_2$ y$u_2$) deben estar correlacionados linealmente. Sin embargo, este último par de vectores tiene un grado de relación lineal inferior al de la primera componente. Esto se debe a que $t_1$ y$u_1$ capturan la mayor fuente de variación y correlación entre X e Y (y por ello son los primeros scores).

```{r tu, fig.width=10, fig.height=5}
# t vs u
par(mfrow = c(2,2))
plot(myplsda@scoreMN[,1], myplsda@uMN[,1], xlab = "t", ylab = "u",
     main = "Component 1", col = "red3", ylim=c(-6, 6), xlim=c(-6, 4))
abline(a=0, b=1, col = "grey", lty = 3, lwd=3)

plot(myplsda@scoreMN[,2], myplsda@uMN[,2], xlab = "t", ylab = "u",
     main = "Component 2", col = "red3", ylim=c(-6, 6), xlim=c(-6, 4))
abline(a=0, b=1, col = "grey", lty = 3, lwd=3)

plot(myplsda@scoreMN[,3], myplsda@uMN[,3], xlab = "t", ylab = "u",
     main = "Component 3", col = "red3", ylim=c(-6, 6), xlim=c(-6, 4))
abline(a=0, b=1, col = "grey", lty = 3, lwd=3)

plot(myplsda@scoreMN[,4], myplsda@uMN[,4], xlab = "t", ylab = "u",
     main = "Component 4", col = "red3", ylim=c(-6, 6), xlim=c(-6, 4))
abline(a=0, b=1, col = "grey", lty = 3, lwd=3)

# correlacion de los scores de las distintas componentes
diag(cor(myplsda@scoreMN, myplsda@uMN))  
```

Distribución variable explicada (grup_todo)
```{r}
boxplot(y_train)
plot(y_train)
```

## Predicción del modelo

```{r}
ypred = predict(myplsda, X_test) 
library(caret)
library(kableExtra)
confusionMatrix(ypred, y_test)

as.table(confusionMatrix(ypred, y_test))
```



Coeficientes del modelo
```{r coeficientes regresion}
coef = myplsda@coefficientMN
coef_ord= sort(coef[,1], decreasing = TRUE)

barplot(coef_ord , col=ifelse(sort(coef[,1], decreasing = TRUE) > 0, 3, 2), main='Gráfico coeficientes regresión', las=2)
```

```{r}
coef = myplsda@coefficientMN
coef1 = sort(coef[,1], decreasing=TRUE)
barplot(coef1, col=ifelse(coef1 > 0, 3, 2), main='Regression coefficient plot Group 1', las=2, cex.names=0.5)

coef2 = sort(coef[,2], decreasing=TRUE)
barplot(coef2, col=ifelse(coef2 > 0, 3, 2), main='Regression coefficient plot Group 2', las=2, cex.names=0.5)

coef3 = sort(coef[,3], decreasing=TRUE)
barplot(coef3, col=ifelse(coef3 > 0, 3, 2), main='Regression coefficient plot Group 3', las=2, cex.names=0.5)

coef4 = sort(coef[,4], decreasing=TRUE)
barplot(coef4, col=ifelse(coef4 > 0, 3, 2), main='Regression coefficient plot Group 4', las=2, cex.names=0.5)

coef5 = sort(coef[,5], decreasing=TRUE)
barplot(coef5, col=ifelse(coef5 > 0, 3, 2), main='Regression coefficient plot Group 5', las=2, cex.names=0.5)

coef6 = sort(coef[,6], decreasing=TRUE)
barplot(coef6, col=ifelse(coef6 > 0, 3, 2), main='Regression coefficient plot Group 6', las=2, cex.names=0.5)

coef7 = sort(coef[,7], decreasing=TRUE)
barplot(coef7, col=ifelse(coef7 > 0, 3, 2), main='Regression coefficient plot Group 7', las=2, cex.names=0.5)
```






# PRUEBA 2: Juntar mutaciones 1 y 2 en 1


Hacer 20 regresiones logísticas, poniendo grupo etiopatogénico como explicativa

```{r}
library(dplyr)
df4 = df2
df4 <- df4 %>% mutate_at(vars(1:20), ~ ifelse(. == 2, 1, .))
df4[] <- lapply(df4, as.factor)

y = as.factor(df4$grupfuz_todo)
X = df4[,!names(df4) %in% c("grupfuz_todo")]
```


## 20 regresiones logísticas
Vamos a hacer 29ç0 regresiones logísticas: 1 por cada gen de reparación del ADN. La variable explicativa será "grupo etiopatogénico", introducida como as.factor. La variable a predecir será cada gen.

```{r}
# Ajuste de un modelo logístico.

mod1 <- glm(XPC_rs2228001 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod1))
mod2 <- glm(XPC_rs2228000 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod2))

mod3 <- glm(NBN_rs1063054 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod3))
mod4 <- glm(NBN_rs709816 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod4))
mod5 <- glm(NBN_rs1805794 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod5))

#grupfuz5 ->0.0418 *
mod6 <- glm(MGMT_rs10829601 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod6))

mod7 <- glm(ATM_rs1801516 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod7))

#grupfuz_todo4: 0.00219 **
#grupfuz_todo5: 0.02649 * 
mod8 <- glm(ERCC5_rs17655 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod8))

mod9 <- glm(XRCC3_rs861539 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod9))
mod10 <- glm(XRCC3_rs861530 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod10))
mod11 <- glm(XRCC3_rs1799794 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod11))

#grupfuz_todo7: 0.0488 *
mod12 <- glm(XRCC1_rs25487 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod12))
mod13 <- glm(XRCC1_rs25489 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod13))
mod14 <- glm(XRCC1_rs3213245 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod14))

#grupfuz_todo2:0.00829 **
#grupfuz_todo5: 0.00621 **
mod15 <- glm(ERCC2_rs13181 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod15))

#grupfuz_todo2: 0.0286 *
mod16 <- glm(ERCC2_rs1799793 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod16))

#grupfuz_todo6: 0.0357 
mod17 <- glm(rs1011970_CDKN2B.AS1 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod17))
mod18 <- glm(rs10757257_MTAP ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod18))
mod19 <- glm(rs2284063_PLA2G6 ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod19))
mod20<- glm(rs7023329_MTAP ~ grupfuz_todo, data = df4, family = "binomial")
print(summary(mod20))

```


Matriz de asociación (categóricas) y juntando los unos y doses:
```{r}
corr_matrix <- model.matrix(~0+., data=df4) %>% 
  cor(use="pairwise.complete.obs")
last_col <- data.frame(grupfuz_todo=c(corr_matrix[, 21]))
ggcorrplot(last_col, show.diag=FALSE, type="lower", lab=TRUE, lab_size=2, colors=c( "#00BFC4", "white", "#F8766D"))

```


# PRUEBA 3: No juntar mutaciones 1 y 2
## 20 regresiones logísticas
Matriz de asociación (categóricas):
```{r}
df3 = df2
df3[] <- lapply(df3, as.factor)

corr_matrix <- model.matrix(~0+., data=df3) %>% 
  cor(use="pairwise.complete.obs")
last_col <- data.frame(grupfuz_todo=c(corr_matrix[, 21]))
ggcorrplot(last_col, show.diag=FALSE, type="lower", lab=TRUE, lab_size=2, colors=c( "#00BFC4", "white", "#F8766D"))
```

```{r}
# Ajuste de un modelo logístico.

mod1 <- glm(XPC_rs2228001 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod1))
p1 <- summary(mod1)$coefficients[,4]


mod2 <- glm(XPC_rs2228000 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod2))
p2 <- summary(mod2)$coefficients[,4]

mod3 <- glm(NBN_rs1063054 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod3))
p3 <- summary(mod3)$coefficients[,4]

mod4 <- glm(NBN_rs709816 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod4))
p4 <- summary(mod4)$coefficients[,4]

mod5 <- glm(NBN_rs1805794 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod5))
p5 <- summary(mod5)$coefficients[,4]


#grupfuz_todo5: 0.0418 *
mod6 <- glm(MGMT_rs10829601 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod6))
p6 <- summary(mod6)$coefficients[,4]

mod7 <- glm(ATM_rs1801516 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod7))
p7 <- summary(mod7)$coefficients[,4]


#grupfuz_todo5. 0.02649 *
mod8 <- glm(ERCC5_rs17655 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod8))
p8 <- summary(mod8)$coefficients[,4]

mod9 <- glm(XRCC3_rs861539 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod9))
p9 <- summary(mod9)$coefficients[,4]

mod10 <- glm(XRCC3_rs861530 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod10))
p10 <- summary(mod10)$coefficients[,4]

mod11 <- glm(XRCC3_rs1799794 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod11))
p11 <- summary(mod11)$coefficients[,4]

#grupfuz_todo7: 0.0488 *
mod12 <- glm(XRCC1_rs25487 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod12))
p12 <- summary(mod12)$coefficients[,4]

mod13 <- glm(XRCC1_rs25489 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod13))
p13 <- summary(mod13)$coefficients[,4]

mod14 <- glm(XRCC1_rs3213245 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod14))
p14 <- summary(mod14)$coefficients[,4]

#grupfuz_todo2:0.00829 **
#grupfuz_todo5: 0.00621 **

mod15 <- glm(ERCC2_rs13181 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod15))
p15 <- summary(mod15)$coefficients[,4]

#grupfuz_todo2: 0.0286 *
mod16 <- glm(ERCC2_rs1799793 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod16))
p16 <- summary(mod16)$coefficients[,4]

#grupfuz_todo6: 0.0357 *
mod17 <- glm(rs1011970_CDKN2B.AS1 ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod17))
p17 <- summary(mod17)$coefficients[,4]

mod18 <- glm(rs10757257_MTAP ~ grupfuz_todo, data = df3, family = "binomial")
p18 <- summary(mod18)$coefficients[,4]
print(summary(mod18))

mod19 <- glm(rs2284063_PLA2G6 ~ grupfuz_todo, data = df3, family = "binomial")
p19 <- summary(mod19)$coefficients[,4]
print(summary(mod19))

mod20<- glm(rs7023329_MTAP ~ grupfuz_todo, data = df3, family = "binomial")
print(summary(mod20))
p20 <- summary(mod20)$coefficients[,4]


df_pvalue= data.frame("p1"=p1, "p2"=p2, "p3"=p3, p4, p5, p6, p7, p8, p9, p10, p11, p12, p13, p14, p15, p16, p17, p18, p19, p20)

colnames(df_pvalue) = colnames(df3[1:20])
df_pvalue = t(df_pvalue)

library(reshape)
p_values = data.frame(melt(df_pvalue))
colnames(p_values)=c("genes", "grupfuz", "pvalue")
```



```{r}

library(tibble)
library(colorspace)
library(ggplot2)
ggplot(p_values, aes(x = grupfuz, y = genes, fill = pvalue)) + geom_tile(color = "white") + 
  scale_fill_continuous_divergingx(palette = "RdBu", limits = c(0.05,1)) +
  guides(fill = guide_colorbar(title = "P-value", barheight = 18)) +
  xlab("Fuzzy groups") +
  ylab("DNA repair genes") +
  ggtitle("Logistic Regression p-value") + theme_bw()
```


# PRUEBA 4: Matrices de correlación?

## Matriz de categóricas
Matriz de asociación (categóricas):
```{r}
df3 = df2
df3[] <- lapply(df3, as.factor)

corr_matrix <- model.matrix(~0+., data=df3) %>% 
  cor(use="pairwise.complete.obs")
last_col <- data.frame(grupfuz_todo=c(corr_matrix[, 21]))
ggcorrplot(last_col, show.diag=FALSE, type="lower", lab=TRUE, lab_size=2, colors=c( "#00BFC4", "white", "#F8766D"))
```

Test de independencia (código de Lucas jeje):

Coger la columna de grupfuz_todo y coger la columna de todos los genes
```{r}
columnas = colnames(df3[1:20])
grup = df3$grupfuz_todo

p_value = c()
for (col in names(df3)) {
  if (col %in% columnas) {
    data = df3[[col]]
    p_value = c(p_value, chisq.test(data, grup)$p.value)}
}

p_value
```



## Matriz de numéricas
Matriz de correlación (numéricos):
```{r}
library(ggcorrplot)
corr_matrix <- model.matrix(~0+., data=df2) %>% 
  cor(use="pairwise.complete.obs")
last_col <- data.frame(grupfuz_todo=c(corr_matrix[, 21]))
ggcorrplot(last_col, show.diag=FALSE, type="lower", lab=TRUE, lab_size=2, colors=c( "#00BFC4", "white", "#F8766D"))
```

Tenemos algunos grupos sabemos en base a qué se forman (variables que más contribuyen a crear estos grupos). Comparar los genes a CSD, en vez de al grupo de CSD. 

Boxplot con CSD, XRC y hacemos 3 boxplot (1 por cada mutación)

```{r}
df32 = df3
df32[1:20] <- lapply(df32, as.numeric)
resultado_kruskal <- kruskal.test(ERCC5_rs17655 ~ grupfuz_todo, data = df32)
resultado_kruskal$p.value
resultado_kruskal
posthoc_dunn <- dunnTest(ERCC5_rs17655 ~ grupfuz_todo, data = df32, method = "bonferroni")
posthoc_dunn
```

